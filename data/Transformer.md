
## NLP

- 2017-06 Attention Is All You Need [[Paper](https://arxiv.org/pdf/1706.03762.pdf)] [[Code](https://nbviewer.jupyter.org/github/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb)] [[Note](https://github.com/junxnone/tech-io/issues/756)]
- 2018-10 **[BERT]**
- 2020-05 **[GPT3]**
- 2020-06 **[Linformer]** Linformer: Self-Attention with Linear Complexity [[Paper](https://arxiv.org/abs/2006.04768)] [[Code](https://github.com/lucidrains/linformer)] [[Note](https://github.com/junxnone/tech-io/issues/932)]  #Optimizition
- 2021-02 **[Nyströmformer]**  A Nyström-Based Algorithm for Approximating Self-Attention [[Paper](https://arxiv.org/abs/2102.03902)] [[Code](https://github.com/mlpen/Nystromformer)] [[Note](https://github.com/junxnone/tech-io/issues/935)] #Optimizition
- 2020-08 **[DeLighT]** DeLighT: Deep and Light-weight Transformer[[Paper](https://arxiv.org/abs/2008.00623)] [[Code](https://github.com/sacmehta/delight)] [[Note](notelink)] #Optimizition


## Vision

- 2020-05 **[DETR]** End-to-End Object Detection with Transformers [[Paper](https://arxiv.org/abs/2005.12872v3)] [[Code](https://github.com/facebookresearch/detr)] [[Note](notelink)] #ObjectDetection #Segmentation
- 2020-07 **[iGPT]** Generative Pretraining from Pixels[[Paper](https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf)] [[Code](https://github.com/openai/image-gpt)] [[Note](notelink)] #Classification
- 2020-09 **[Performer]** Rethinking Attention with Performers  [[paper](https://arxiv.org/pdf/2009.14794.pdf)] [[Code](https://github.com/google-research/google-research/tree/master/performer)] [[Note](https://github.com/junxnone/tech-io/issues/925)]
- 2020-10 **[ViT]** An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale [[Paper](https://arxiv.org/abs/2010.11929)] [[Code](https://github.com/google-research/vision_transformer)] [[Note](https://github.com/junxnone/tech-io/issues/916)] #Classification
- 2020-10 **[Deformable DETR]** Deformable DETR: Deformable Transformers for End-to-End Object Detection(**ICLR**)[[paper](https://arxiv.org/abs/2010.04159)] [[code](https://github.com/fundamentalvision/Deformable-DETR)] [[Note](notelink)]
- 2020-11 **[UP-DETR]** UP-DETR: Unsupervised Pre-training for Object Detection with Transformers [[Paper](https://arxiv.org/abs/2011.09094)] [[Code](codelink)] [[Note](notelink)]
- 2020-11 **[LSTR]** End-to-end Lane Shape Prediction with Transformers [[Paper](https://arxiv.org/pdf/2011.04233.pdf)] [[Code](https://github.com/liuruijin17/LSTR)] [[Note](notelink)] #LaneDetection
- 2020-12 **[IPT]** Pre-Trained Image Processing Transformer [[Paper](https://arxiv.org/abs/2012.00364)] [[Code](codelink)] [[Note](notelink)] #denoising #super-resolution
- 2020-12 **[DeiT]** Training data-efficient image transformers & distillation through attention [[Paper](https://arxiv.org/abs/2012.12877)] [[Code](https://github.com/facebookresearch/deit)]  [[Note](https://github.com/junxnone/tech-io/issues/931)]
- 2021-01 **[BoTNet]** Bottleneck Transformers for Visual Recognition [[Paper](https://arxiv.org/abs/2101.11605)] [[Code](https://paperswithcode.com/paper/bottleneck-transformers-for-visual#code)]  [[Note](https://github.com/junxnone/tech-io/issues/929)]
- 2021-01 **[T2T-ViT]** Tokens-to-Token ViT: Training Vision Transformers from Scratch on ImageNet [[Paper](https://arxiv.org/abs/2101.11986)] [[Code](https://github.com/yitu-opensource/T2T-ViT)] [[Note](https://github.com/junxnone/tech-io/issues/928)] #Classification
- 2021-02 **[PVT]** Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions[[Paper](https://arxiv.org/abs/2102.12122)] [[Code](https://github.com/whai362/PVT)] [[Note](https://github.com/junxnone/tech-io/issues/939)] #Backbone
- 2021-02 **[TNT]** Transformer in Transformer[[Paper](https://arxiv.org/abs/2103.00112)] [[Code](https://github.com/huawei-noah/noah-research/tree/master/TNT)] [[Note](https://github.com/junxnone/tech-io/issues/940)] #Classification
- 2021-03 **[Swin-Transformer]** Swin Transformer: Hierarchical Vision Transformer using Shifted Windows[[Paper](https://arxiv.org/abs/2103.14030)] [[Code](https://github.com/microsoft/Swin-Transformer)] [[Note](https://github.com/junxnone/tech-io/issues/958)] #Backbone 

## Survey



- 2020-09 Efficient Transformers: A Survey [[Paper](https://arxiv.org/abs/2009.06732)] [[Note](https://github.com/junxnone/tech-io/issues/934)]
- 2021-01 A Survey on Visual Transformer [[Paper](https://arxiv.org/pdf/2012.12556.pdf)]  [[Note](https://github.com/junxnone/tech-io/issues/926)]
- 2021-01 Transformers in Vision: A Survey [[Paper](https://arxiv.org/pdf/2101.01169.pdf)]  [[Note](https://github.com/junxnone/tech-io/issues/927)]
